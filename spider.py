import json
import re
import requests
import pandas as pd
from bs4 import BeautifulSoup
from typing import List, Dict, Optional

CONFIG = {
    "base_web_url": "https://arcadezone.cn/ranking#timetrial",
    "api_url": "https://arcadezone.cn/ranking/timetrial",
    "season": 5,
    "headers": {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/130.0.0.0 Safari/537.36",
        "Content-Type": "application/json",
        "Accept": "application/json, text/plain, */*",
        "Referer": "https://arcadezone.cn/ranking#timetrial",
        "Origin": "https://arcadezone.cn",
    },
    "player_id_path": "Player_ID.dat",
    "standard_time_path": "./assets/rank.csv",  # æ ‡å‡†ç­‰çº§æ—¶é—´åº“è·¯å¾„
    "timeout": 30,
    "max_retry": 3,
    "course_name_map": {
        0: "ç§‹åæ¹–",
        2: "ç§‹åæ¹–",
        4: "å¦™ç¾©",
        6: "å¦™ç¾©",
        8: "èµ¤åŸ",
        10: "èµ¤åŸ",
        12: "ç§‹å",
        14: "ç§‹å",
        16: "ä¼Šå•æ³¢å‚",
        18: "ä¼Šå•æ³¢å‚",
        20: "ç­‘æ³¢",
        22: "ç­‘æ³¢",
        24: "å…«æ–¹åŸ",
        26: "å…«æ–¹åŸ",
        28: "é•¿å°¾",
        30: "é•¿å°¾",
        32: "æ¤¿çº¿",
        34: "æ¤¿çº¿",
        36: "ç¢“å†°",
        38: "ç¢“å†°",
        40: "å®šå³°",
        42: "å®šå³°",
        44: "åœŸå‚",
        46: "åœŸå‚",
        48: "ç§‹åé›ª",
        50: "ç§‹åé›ª",
        52: "ç®±æ ¹",
        54: "ç®±æ ¹",
        56: "æ«æ ‘çº¿",
        58: "æ«æ ‘çº¿",
        60: "ä¸ƒæ›²",
        62: "ä¸ƒæ›²",
        64: "ç¾¤é¦¬èµ›è½¦åœº",
        66: "ç¾¤é¦¬èµ›è½¦åœº",
        68: "å°ç”°åŸ",
        70: "å°ç”°åŸ",
        72: "ç­‘æ³¢é›ª",
        74: "ç­‘æ³¢é›ª",
        76: "çŸ¢çŸ©",
        78: "çŸ¢çŸ©",
        80: "åœŸå‚é›ª",
        82: "åœŸå‚é›ª",
        84: "çœŸé¹¤",
        86: "çœŸé¹¤",
        88: "ç¢“å†°é›ª",
        90: "ç¢“å†°é›ª",
        92: "ç§‹åé›¨",
        94: "ç§‹åé›¨"
    },
    "course_direction_map": {
        0: "é€†æ—¶é’ˆ",
        2: "é¡ºæ—¶é’ˆ",
        4: "ä¸‹å¡",
        6: "ä¸Šå¡",
        8: "ä¸‹å¡",
        10: "ä¸Šå¡",
        12: "ä¸‹å¡",
        14: "ä¸Šå¡",
        16: "ä¸‹å¡",
        18: "é€†è¡Œ",
        20: "å»è·¯",
        22: "å½’è·¯",
        24: "å»è·¯",
        26: "å½’è·¯",
        28: "ä¸‹å¡",
        30: "ä¸Šå¡",
        32: "ä¸‹å¡",
        34: "ä¸Šå¡",
        36: "é€†æ—¶é’ˆ",
        38: "é¡ºæ—¶é’ˆ",
        40: "ä¸‹å¡",
        42: "ä¸Šå¡",
        44: "å»è·¯",
        46: "å½’è·¯",
        48: "ä¸‹å¡",
        50: "ä¸Šå¡",
        52: "ä¸‹å¡",
        54: "ä¸Šå¡",
        56: "ä¸‹å¡",
        58: "ä¸Šå¡",
        60: "ä¸‹å¡",
        62: "ä¸Šå¡",
        64: "å»è·¯",
        66: "å½’è·¯",
        68: "é¡ºè¡Œ",
        70: "é€†è¡Œ",
        72: "å»è·¯",
        74: "å½’è·¯",
        76: "ä¸‹å¡",
        78: "ä¸Šå¡",
        80: "å»è·¯",
        82: "å½’è·¯",
        84: "é¡ºè¡Œ",
        86: "é€†è¡Œ",
        88: "é€†æ—¶é’ˆ",
        90: "é¡ºæ—¶é’ˆ",
        92: "ä¸‹å¡",
        94: "ä¸Šå¡"
    },
    "rank_priority": ["LEGEND", "MASTER+", "MASTER", "PROFESSIONAL", "EXPERT", "SPECIALIST", "REGULAR"]
}

class ArcadeZoneCrawler:
    def __init__(self):
        self.headers = CONFIG["headers"]
        self.api_url = CONFIG["api_url"]
        self.base_web_url = CONFIG["base_web_url"]
        self.season = CONFIG["season"]
        self.target_username = self._load_target_username()
        self.standard_times = self._load_standard_times()  # åŠ è½½ç­‰çº§æ ‡å‡†åº“
        self.session = requests.Session()
        self._get_csrf_token()

    def _load_target_username(self) -> str:
        try:
            with open(CONFIG["player_id_path"], "r", encoding="utf-8") as f:
                line = f.readline().strip()
                if line.startswith("ID = "):
                    username = line.split("ID = ")[1].strip()
                    print(f"âœ… æˆåŠŸåŠ è½½ç›®æ ‡ç”¨æˆ·ï¼š{username}")
                    return username
                else:
                    raise ValueError("é…ç½®æ–‡ä»¶æ ¼å¼é”™è¯¯ï¼Œæ­£ç¡®æ ¼å¼ï¼šID = ç”¨æˆ·å")
        except FileNotFoundError:
            raise Exception(f"âŒ æœªæ‰¾åˆ°é…ç½®æ–‡ä»¶ï¼š{CONFIG['player_id_path']}")
        except Exception as e:
            raise Exception(f"âŒ è¯»å–é…ç½®æ–‡ä»¶å¤±è´¥ï¼š{str(e)}")

    def _load_standard_times(self) -> pd.DataFrame:
        try:
            df = pd.read_csv(CONFIG["standard_time_path"], encoding="utf-8-sig")
            required_cols = ["Course", "Direction"] + CONFIG["rank_priority"]
            for col in required_cols:
                if col not in df.columns:
                    raise Exception(f"æ ‡å‡†åº“ç¼ºå°‘å¿…å¡«åˆ—ï¼š{col}ï¼Œè¯·æ£€æŸ¥CSVæ–‡ä»¶")
            for rank in CONFIG["rank_priority"]:
                df[rank] = df[rank].fillna("99'99\"999")
            print(f"âœ… æˆåŠŸåŠ è½½ç­‰çº§æ ‡å‡†åº“ï¼Œå…±{len(df)}æ¡èµ›é“æ ‡å‡†")
            return df
        except FileNotFoundError:
            raise Exception(f"âŒ æœªæ‰¾åˆ°ç­‰çº§æ ‡å‡†åº“ï¼š{CONFIG['standard_time_path']}")
        except Exception as e:
            raise Exception(f"âŒ è¯»å–ç­‰çº§æ ‡å‡†åº“å¤±è´¥ï¼š{str(e)}")

    def _get_csrf_token(self):
        """è·å–CSRF Token"""
        try:
            response = self.session.get(
                self.base_web_url,
                headers=self.headers,
                timeout=CONFIG["timeout"]
            )
            response.raise_for_status()
            soup = BeautifulSoup(response.text, "html.parser")
            csrf_meta = soup.find("meta", attrs={"name": "csrf-token"})
            if csrf_meta:
                csrf_token = csrf_meta.get("content")
                self.headers["X-CSRF-TOKEN"] = csrf_token
                print(f"âœ… æˆåŠŸè·å–CSRF Tokenï¼š{csrf_token[:10]}...")
            else:
                raise Exception("ç½‘é¡µä¸­æœªæ‰¾åˆ°CSRF Token")
        except Exception as e:
            raise Exception(f"âŒ è·å–CSRF Tokenå¤±è´¥ï¼š{str(e)}")

    def _str_time_to_ms(self, time_str: str) -> int:
        try:
            if ":" in time_str and "." in time_str:
                minute, rest = time_str.split(":")
                second, ms = rest.split(".")
                return int(minute)*60000 + int(second)*1000 + int(ms)
            elif "'" in time_str and "\"" in time_str:
                minute, rest = time_str.split("'")
                second, ms = rest.split("\"")
                return int(minute)*60000 + int(second)*1000 + int(ms)
            else:
                return 99999999  # å¼‚å¸¸æ ¼å¼è¿”å›æå¤§å€¼
        except:
            return 99999999

    def _judge_rank(self, course: str, direction: str, score_ms: int) -> str:
        mask = (self.standard_times["Course"] == course) & (self.standard_times["Direction"] == direction)
        if not mask.any():
            print(f"âš ï¸  æœªæ‰¾åˆ°{course}-{direction}çš„ç­‰çº§æ ‡å‡†ï¼Œé»˜è®¤æœªçŸ¥è¯„ä»·")
            return "æœªçŸ¥è¯„ä»·"
        
        # è·å–æ ‡å‡†è¡Œæ•°æ®
        standard_row = self.standard_times[mask].iloc[0]
        for rank in CONFIG["rank_priority"]:
            standard_ms = self._str_time_to_ms(str(standard_row[rank]))
            if score_ms <= standard_ms:
                return rank
        
        # æ‰€æœ‰é«˜çº§æ ‡å‡†éƒ½ä¸æ»¡è¶³ï¼Œåˆ¤å®šä¸ºROOKIE
        return "ROOKIE"

    def _request_api(self, page: int, course_id: int) -> Optional[Dict]:
        payload = {
            "page": page,
            "season": self.season,
            "course": course_id
        }
        for retry in range(CONFIG["max_retry"]):
            try:
                response = self.session.post(
                    url=self.api_url,
                    headers=self.headers,
                    data=json.dumps(payload, ensure_ascii=False),
                    timeout=CONFIG["timeout"]
                )
                response.raise_for_status()
                return response.json()
            except requests.exceptions.RequestException as e:
                print(f"âš ï¸  ç¬¬{retry+1}æ¬¡è¯·æ±‚å¤±è´¥ï¼Œèµ›é“{course_id}ç¬¬{page}é¡µï¼š{str(e)}")
                if retry == CONFIG["max_retry"] - 1:
                    print(f"âŒ èµ›é“{course_id}ç¬¬{page}é¡µè¯·æ±‚æœ€ç»ˆå¤±è´¥ï¼Œè·³è¿‡è¯¥é¡µ")
                    return None

    def _parse_time(self, ms: int) -> str:
        minutes = ms // 60000
        seconds = (ms % 60000) // 1000
        millis = ms % 1000
        return f"{minutes}:{seconds:02d}.{millis:03d}"

    def _parse_rank_data(self, data: Dict, course_id: int, current_page: int) -> List[Dict]:
        result = []
        rank_list = data.get("list", [])
        car_styles_map = data.get("carStyles", {})
        course_name = CONFIG["course_name_map"].get(course_id, "æœªçŸ¥èµ›é“")
        direction = CONFIG["course_direction_map"].get(course_id, "æœªçŸ¥æ–¹å‘")

        per_page = data.get("pagination", {}).get("per_page", 15)

        for idx, item in enumerate(rank_list):
            user_info = item.get("userinfo", {})
            username = user_info.get("username", "")
            if username != self.target_username:
                continue

            national_rank = (current_page - 1) * per_page + idx + 1
            car_id = str(item.get("style_car_id", ""))
            car_name = car_styles_map.get(car_id, "æœªçŸ¥è½¦å‹")
            goal_time_ms = item.get("goal_time", 0)
            time_str = self._parse_time(goal_time_ms)
            play_time = item.get("play_dt", "").split(" ")[0]

            time_eval = self._judge_rank(course_name, direction, goal_time_ms)
            print(f"[åˆ¤æ–­] {course_name}({direction}) | æˆç»©ï¼š{time_str} â†’ ç­‰çº§ï¼š{time_eval}")

            rank_info = {
                "ã‚³ãƒ¼ã‚¹": course_name,
                "ãƒ«ãƒ¼ãƒˆ": direction,
                "ã‚¿ã‚¤ãƒ ": time_str,
                "ã‚¿ã‚¤ãƒ è©•ä¾¡": time_eval,
                "è¨˜éŒ²è»Šç¨®": car_name,
                "å…¨å›½é †ä½": str(national_rank),
                "è¨˜éŒ²æ—¥": play_time
            }
            result.append(rank_info)
        return result

    def crawl_course(self, course_id: int) -> List[Dict]:
        course_name = CONFIG["course_name_map"].get(course_id, "æœªçŸ¥èµ›é“")
        direction = CONFIG["course_direction_map"].get(course_id, "æœªçŸ¥æ–¹å‘")
        print(f"\n========== å¼€å§‹çˆ¬å– èµ›é“ID:{course_id}ï¼ˆ{course_name}({direction})ï¼‰ ==========")
        all_matched_data = []

        first_page_data = self._request_api(page=1, course_id=course_id)
        if not first_page_data:
            return all_matched_data

        page1_data = self._parse_rank_data(first_page_data, course_id, current_page=1)
        all_matched_data.extend(page1_data)

        total_pages = first_page_data.get("pagination", {}).get("last_page", 1)
        print(f"âœ… èµ›é“{course_id} æ€»é¡µæ•°ï¼š{total_pages}")

        for page in range(2, total_pages + 1):
            print(f"æ­£åœ¨çˆ¬å– èµ›é“{course_id} ç¬¬{page}/{total_pages}é¡µ...",end='\r')
            page_data = self._request_api(page=page, course_id=course_id)
            if not page_data:
                continue
            matched_data = self._parse_rank_data(page_data, course_id, current_page=page)
            all_matched_data.extend(matched_data)

        print(f"========== èµ›é“{course_id} çˆ¬å–å®Œæˆï¼ŒåŒ¹é…åˆ°{len(all_matched_data)}æ¡æˆç»© ==========\n")
        return all_matched_data

    def run(self, course_list: List[int], return_df: bool = False) -> Optional[pd.DataFrame]:
        final_result = []
        for course_id in course_list:
            data = self.crawl_course(course_id)
            final_result.extend(data)

        if not final_result:
            print(f"âŒ æœªåŒ¹é…åˆ°{self.target_username}çš„ä»»ä½•æˆç»©è®°å½•")
            if return_df:
                return pd.DataFrame()
            return None

        # ä¿æŒåŸæœ‰è¾“å‡ºæ ¼å¼
        csv_columns = ["ã‚³ãƒ¼ã‚¹", "ãƒ«ãƒ¼ãƒˆ", "ã‚¿ã‚¤ãƒ ", "ã‚¿ã‚¤ãƒ è©•ä¾¡", "è¨˜éŒ²è»Šç¨®", "å…¨å›½é †ä½", "è¨˜éŒ²æ—¥"]
        df = pd.DataFrame(final_result)[csv_columns]
        
        if not return_df:
            csv_filename = f"DAC_{self.target_username}_æˆç»©è¡¨.csv"
            df.to_csv(csv_filename, index=False, encoding="utf-8-sig")

            # æ§åˆ¶å°è¾“å‡ºç»“æœ
            print("=" * 80)
            print(f"ğŸ¯ çˆ¬å–ä»»åŠ¡å…¨éƒ¨å®Œæˆï¼æ€»è®¡åŒ¹é…åˆ°{len(final_result)}æ¡æˆç»©")
            print(f"âœ… CSVæ–‡ä»¶å·²ä¿å­˜ï¼š{csv_filename}")
            print("=" * 80)
            print("\nã€æˆç»©é¢„è§ˆã€‘")
            print(df.to_string(index=False))
        
        return df if return_df else None

# å¯¹å¤–æš´éœ²çš„çˆ¬å–å‡½æ•°ï¼ˆä¾›coreè°ƒç”¨ï¼‰
def crawl_data() -> pd.DataFrame:
    # é…ç½®éœ€è¦çˆ¬å–çš„èµ›é“IDåˆ—è¡¨
    TARGET_COURSES = [0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32, 34, 36, 38, 40, 42, 44, 46, 48, 50, 52, 54, 56, 58, 60, 62, 64, 66, 68, 70, 72, 74, 76, 78, 80, 82, 84, 86, 88, 90, 92, 94]

    try:
        crawler = ArcadeZoneCrawler()
        df = crawler.run(TARGET_COURSES, return_df=True)
        return df
    except Exception as e:
        print(f"âŒ çˆ¬è™«æ‰§è¡Œå¤±è´¥ï¼š{str(e)}")
        return pd.DataFrame()

if __name__ == "__main__":
    # ç‹¬ç«‹è¿è¡Œçˆ¬è™«çš„é€»è¾‘
    TARGET_COURSES = [0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32, 34, 36, 38, 40, 42, 44, 46, 48, 50, 52, 54, 56, 58, 60, 62, 64, 66, 68, 70, 72, 74, 76, 78, 80, 82, 84, 86, 88, 90, 92, 94]

    try:
        crawler = ArcadeZoneCrawler()
        crawler.run(TARGET_COURSES)
    except Exception as e:
        print(f"âŒ ç¨‹åºè¿è¡Œå¤±è´¥ï¼š{str(e)}")
